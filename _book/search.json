[
  {
    "objectID": "entries/2025-09-03-1.html",
    "href": "entries/2025-09-03-1.html",
    "title": "2  2025-09-03",
    "section": "",
    "text": "2.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-1.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-03-1.html#choose-one-prompt-to-answer",
    "title": "2  2025-09-03",
    "section": "",
    "text": "Prompt A: Think about a claim you’ve seen online that you weren’t sure was true. How would the principles of empiricism and control help you design a study to test whether it was accurate?\n\n\nPrompt B: Choose a topic you’re curious about in media or communication (e.g., the effect of streaming on movie watching, how politicians use TikTok, portrayals of families on TV). Write a specific research question about it. Then, briefly describe what you would do in each of the five stages of the research workflow (Conceptualization, Design, Data Collection, Data Analysis, Communication) to answer it.\n\n\nPrompt C: Describe a time you learned a digital tool (in any context—school, work, a hobby) without really understanding the reasoning behind what you were doing. How might knowing the “why”—the tool-agnostic principles—have helped you use it more effectively, solve problems, or even choose a better tool for the task?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-1.html#response",
    "href": "entries/2025-09-03-1.html#response",
    "title": "2  2025-09-03",
    "section": "2.2 Response",
    "text": "2.2 Response\n\nOne claim I recently came across online stated that “Making your bed every day makes you 206% more likely to become a millionaire.” While this statement is catchy and might be intended to motivate people toward discipline and success, I was immediately skeptical of its accuracy. To evaluate whether this claim holds any truth, I would apply the principles of empiricism and control to design a study that could test it objectively. Empiricism is the idea that knowledge should be based on observable and measurable evidence. Rather than accepting the claim at face value, I would gather real-world data to see if there is any actual correlation between bed-making habits and income level. To do this, I would conduct a survey targeting a diverse sample of participants across different age groups, professions, and socioeconomic backgrounds. The survey would collect demographic data such as age, gender, education level, occupation, and current salary range. This would help ensure that the sample is representative and that the results are meaningful. In addition to demographic information, the survey would ask participants about their bed-making habits using a Likert-style scale. The question might be phrased as: “How often do you make your bed in the morning?” with response options including: Always, Most of the time, Sometimes, Rarely, Never. This format allows for a more nuanced understanding of behavior rather than a simple yes/no answer. The principle of control is equally important in designing a reliable study. Control involves accounting for other variables that might influence the outcome. In this case, factors such as education level, industry, geographic location, and work experience could all affect a person’s income independently of whether they make their bed. By controlling for these variables—either through statistical methods or by segmenting the data—I could better isolate whether bed-making has any real influence on financial success. After collecting and analyzing the data, I would look for patterns or correlations between bed-making frequency and income level. If a strong, statistically significant relationship exists even after controlling for other factors, it might suggest that the claim has some merit. However, if no meaningful correlation is found, it would indicate that the claim is likely exaggerated or unfounded. In conclusion, using empiricism and control allows us to move beyond flashy claims and test ideas with evidence. This approach helps ensure that conclusions are based on facts rather than assumptions or viral internet posts.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-1.html#word-count-range-check",
    "href": "entries/2025-09-03-1.html#word-count-range-check",
    "title": "2  2025-09-03",
    "section": "2.3 Word Count & Range Check",
    "text": "2.3 Word Count & Range Check\n\n\n**Word count:** 0  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ❌ Out of range",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-2.html",
    "href": "entries/2025-09-03-2.html",
    "title": "3  2025-09-03-2",
    "section": "",
    "text": "3.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>2025-09-03-2</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-2.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-03-2.html#choose-one-prompt-to-answer",
    "title": "3  2025-09-03-2",
    "section": "",
    "text": "Prompt B: Imagine you are researching a public social media platform like X (formerly Twitter), Reddit, or TikTok. Would you consider the content you’re analyzing to be public or private? Would you need to obtain informed consent? Why or why not? Reflect on the ethical gray areas that emerge in digital research and how you would navigate them.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>2025-09-03-2</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-2.html#response",
    "href": "entries/2025-09-03-2.html#response",
    "title": "3  2025-09-03-2",
    "section": "3.2 Response",
    "text": "3.2 Response\n\nIf I were researching public social media platforms like X (formerly Twitter), Reddit, or TikTok, I would generally consider the content posted on these platforms to be public information. These platforms are designed for users to share thoughts, opinions, and media with a broad audience, often with the understanding that their posts may be viewed by strangers, especially if they keep their profiles on public. However, just because content is publicly accessible does not mean it is ethically straightforward to use in research. When analyzing posts from individual users, I believe it is important to approach the situation with sensitivity and respect for privacy. Even if a post is technically public, the user may not expect their content to be cited in academic or professional research. In these cases, I would either seek informed consent from the user or anonymize the post to protect their identity. This includes removing usernames, handles, and any other identifying information. Ethically, this helps avoid exposing individuals to unwanted attention or misinterpretation, especially if the content is personal, controversial, or emotionally charged. On the other hand, when referencing content from businesses or organizations on social media, I would consider that information to be public and appropriate to cite without obtaining consent—especially when the content is focused solely on the company or brand, such as advertising campaigns or promotional posts. Companies typically use social media for marketing, branding, and public communication, and their posts are intended to be seen and shared widely. As such, referencing a business’s post or image in research—especially when analyzing trends, engagement, or branding strategies—does not usually raise the same ethical concerns as citing individual users. That said, digital research presents many ethical gray areas. For example, what if a user deletes a post after it has been archived or cited? What if the content was shared publicly but originated from a private group or context? These scenarios challenge researchers to think critically about consent, context, and the potential impact of their work. Additionally, platforms like Reddit often include pseudonymous users who may not expect their posts to be linked to real-world identities, even if the content is public. What if the content is inappropriate, triggering, or vulgar? In such cases, researchers must carefully evaluate whether including the material serves a meaningful purpose in the study and how its inclusion might affect readers or participants. Sensitivity to context and audience is essential, and steps should be taken to provide content warnings or avoid unnecessary exposure to harmful material. To navigate these complexities, I would follow ethical research guidelines, such as those provided by institutional review boards (IRBs), and prioritize transparency, consent, and anonymity whenever possible. I would also consider the intent behind the post and the potential consequences and risk of including it in my research. Ultimately, ethical digital research requires balancing the accessibility of online content with a deep respect for the individuals behind it.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>2025-09-03-2</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03-2.html#word-count-range-check",
    "href": "entries/2025-09-03-2.html#word-count-range-check",
    "title": "3  2025-09-03-2",
    "section": "3.3 Word Count & Range Check",
    "text": "3.3 Word Count & Range Check\n\n\n**Word count:** 0  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ❌ Out of range",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>2025-09-03-2</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03.html",
    "href": "entries/2025-09-03.html",
    "title": "4  2025-09-03",
    "section": "",
    "text": "4.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-03.html#choose-one-prompt-to-answer",
    "title": "4  2025-09-03",
    "section": "",
    "text": "Prompt A: Think of a media-related issue or question you find interesting (e.g., misinformation on social media, representation in film, streaming habits). Now imagine researching that issue without using any theory—just collecting facts. What would be missing from your findings? Reflect on how theory might deepen or improve your ability to explain or understand the issue. What questions might theory help you ask?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03.html#response",
    "href": "entries/2025-09-03.html#response",
    "title": "4  2025-09-03",
    "section": "4.2 Response",
    "text": "4.2 Response\n\nThe source of the claim that “one egg a day is equivalent to five cigarettes” was a 2012 study published in the journal Atherosclerosis. The study found that individuals who consumed more than three egg yolks per week had increased plaque buildup in their carotid arteries. The researchers noted that the effect of egg yolks on plaque buildup was about two-thirds that of smoking cigarettes. However, this nuanced finding was sensationalized by media headlines, leading to widespread misinformation. The comparison was taken out of context and used to support various agendas, particularly within vegan advocacy groups and documentaries. Personally, I first encountered this claim in the Netflix documentary Food, Inc., and it stuck with me for nearly a decade. The way it was presented made me question my own dietary choices, even though I later learned the claim was misleading. This documentary is just one example of a larger issue: the frequent spread of exaggerated or misleading health claims, especially those tied to weight loss. Social media platforms are saturated with content pushing weight loss agendas, often targeting vulnerable individuals who are actively seeking help or guidance. These claims are rarely backed by solid evidence and often exploit emotional appeals or fear-based messaging to gain traction. If I were to research this issue without using any theory, I would likely focus only on collecting statistical media data—comparing viewing statistics or engagement analytics. While this might provide some factual insights, it would miss critical dimensions of the issue, such as how and why the misinformation spread, and what factors influenced its acceptance. Without theory, I wouldn’t explore the social, psychological, or cultural dynamics that shape public understanding. Theory helps us ask deeper questions, such as: What role does media framing play in shaping public perception of health risks? How do confirmation bias and identity (e.g., dietary choices, ethical beliefs) affect how people interpret health claims? What mechanisms allow misinformation to gain traction and credibility on social platforms? Using theory—such as media framing theory, health communication models, or social identity theory—would allow me to approach the research more holistically. I would begin with in-depth interviews, asking participants about their confidence in making health-related decisions, where they typically receive health information (e.g., social media or medical professionals), their physical activity levels, and their eating habits. During open coding, I would look for recurring themes in participants’ responses, such as statements like, “I’m always looking to social media for nutrition information that comes from informal videos.” I might code this as “Trusting social media.” As I move into axial coding, I would begin grouping related codes—such as “Not fact-checking” and “Trusting social media”—under broader categories like “Reliance on informal sources” or “Low information verification.” Finally, in the selective coding phase, I would identify a core category—perhaps “Low information verification”—that ties the data together. From there, I could develop a grounded theory suggesting that individuals with low physical activity and low confidence in their health decisions are more likely to rely on unverified nutrition information from social media.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-03.html#word-count-range-check",
    "href": "entries/2025-09-03.html#word-count-range-check",
    "title": "4  2025-09-03",
    "section": "4.3 Word Count & Range Check",
    "text": "4.3 Word Count & Range Check\n\n\n**Word count:** 0  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ❌ Out of range",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2025-09-03</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-15.html",
    "href": "entries/2025-09-15.html",
    "title": "5  2025-09-15",
    "section": "",
    "text": "5.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2025-09-15</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-15.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-15.html#choose-one-prompt-to-answer",
    "title": "5  2025-09-15",
    "section": "",
    "text": "Prompt B: Think about a media-related topic that interests you (e.g., influencer culture, video game violence, media portrayals of mental health). Now imagine you are preparing to write a literature review on that topic. What kind of “gap” would you look for to justify a new study? Would it be a topical void, a contradiction, or an overlooked perspective? Why does that kind of gap matter in media research?",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2025-09-15</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-15.html#response",
    "href": "entries/2025-09-15.html#response",
    "title": "5  2025-09-15",
    "section": "5.2 Response",
    "text": "5.2 Response\n\nA media-related topic that interests me is electronic word-of-mouth (eWOM) and how it influences consumer behavior and purchase decisions. eWOM refers to any positive or negative statement made by potential, actual, or former customers about a product or company, which is made available to a multitude of people and institutions via the internet. With the rise of social media platforms, eWOM has become a powerful force in shaping consumer perceptions and driving engagement. I recently read the article “Electronic word of mouth and consumer engagement on social media: A literature analysis” by Ismagilova et al. (2020), which provided a comprehensive overview of existing research on eWOM. One of the key takeaways from the article was the identification of several topical voids in the current literature. For example, while many studies have examined the impact of eWOM on purchase intentions, fewer have explored the emotional and psychological mechanisms that underlie consumer responses to eWOM. Specifically, the role of sentiment, tone, and emotional appeal in eWOM messages remains under-researched. This gap is important because emotional content can significantly influence how consumers interpret and act on online reviews and recommendations. Another notable gap is the lack of cross-cultural research in the field. The article points out that most studies on eWOM are conducted in Western contexts, which limits the generalizability of findings. Cultural factors can influence how consumers perceive credibility, trustworthiness, and relevance of eWOM. For instance, collectivist cultures may place more emphasis on community opinions, while individualist cultures may prioritize personal experiences. Exploring these cultural differences could provide a more nuanced understanding of eWOM’s global impact. Additionally, the article highlights a need for more research on platform-specific dynamics. Different social media platforms have unique affordances and user behaviors, which can affect how eWOM is generated, shared, and received. For example, the brevity of Twitter posts versus the visual nature of Instagram content may lead to different consumer engagement patterns. Understanding these platform-specific nuances could help marketers tailor their strategies more effectively. In preparing to write a literature review on eWOM, I would focus on identifying these topical voids and overlooked perspectives as justification for a new study. These gaps matter in media research because they highlight areas where our understanding is incomplete or biased. Addressing them can lead to more inclusive, accurate, and actionable insights. This topic is especially relevant to me personally, as I am in the process of starting my own business and preparing to launch a new product campaign. Understanding how eWOM influences consumer decision-making will be critical in shaping my marketing strategy. Moreover, filling these gaps can help businesses better understand consumer behavior, improve customer engagement strategies, and enhance the effectiveness of digital marketing campaigns. Ultimately, identifying and addressing gaps in media research—whether they are topical voids, contradictions, or overlooked perspectives—is essential for advancing the field and ensuring that research remains relevant in a rapidly evolving digital landscape.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2025-09-15</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-15.html#word-count-range-check",
    "href": "entries/2025-09-15.html#word-count-range-check",
    "title": "5  2025-09-15",
    "section": "5.3 Word Count & Range Check",
    "text": "5.3 Word Count & Range Check\n\n\n**Word count:** 0  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ❌ Out of range",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>2025-09-15</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Course Journal",
    "section": "",
    "text": "This journal renders as a book. Each dated entry is a chapter.\n\nMC 451 entries: 250–300 words\nAt the end of each chapter you’ll see three prompts. Answer only one.\nWrite your answer in the Response box; the page shows an automatic word count and whether you’re in range.\n\n\n0.0.1 Add a new entry\n\nIn R, run: source(\"scripts/new_journal_entry.R\")\nA new chapter like entries/2025-09-01.qmd appears with three prompts injected.\nThe script updates _quarto.yml so the new entry is included in the book.\nRender the book: click Render in RStudio or run quarto render.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Journal Home</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-28.html",
    "href": "entries/2025-09-28.html",
    "title": "7  2025-09-28",
    "section": "",
    "text": "7.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>2025-09-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-28.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-28.html#choose-one-prompt-to-answer",
    "title": "7  2025-09-28",
    "section": "",
    "text": "Prompt B: Imagine you are planning a study on how college students interact with AI tools like ChatGPT. Would you choose a probability sampling method or a non-probability one? Why? Consider your research goals—do you want to generalize to all college students or understand a specific group more deeply? Explain your choice and what trade-offs it involves in terms of access, time, cost, and generalizability.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>2025-09-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-28.html#response",
    "href": "entries/2025-09-28.html#response",
    "title": "7  2025-09-28",
    "section": "7.2 Response",
    "text": "7.2 Response\n\nIf I were planning a study on how college students interact with AI tools like ChatGPT, I would choose a non-probability sampling method. This decision is based on both the nature of the research and the practical considerations involved in conducting the study. Since AI tools like ChatGPT are relatively new and rapidly evolving, there is limited existing research and few established theories. Therefore, my study would likely focus on exploratory research questions rather than testing a specific hypothesis. The goal would be to gain a deeper understanding of how students use these tools, what motivates their usage, and how it affects their academic behavior. Non-probability sampling methods, such as convenience sampling or purposive sampling, are well-suited for exploratory research. These methods allow researchers to select participants who are readily accessible or who meet specific criteria relevant to the study. If I were to use convenience sampling, I might distribute my survey electronically to students on a single university campus, targeting those who are easily accessible. Alternatively, if I opted for purposive sampling, I would intentionally select students who are known to use ChatGPT regularly or who are enrolled in courses that promote the use of AI tools. Either of these approaches would help me gather insights from a targeted group, even if the findings are not statistically generalizable to all college students. One of the key trade-offs in choosing non-probability sampling is generalizability. Unlike probability sampling, which uses random selection to ensure that every member of the population has an equal chance of being included, non-probability sampling does not support broad generalizations. However, in the early stages of research—especially when studying emerging technologies—depth of understanding can be more valuable. The insights gained from a focused group can inform future studies that may use probability sampling to test hypotheses on a larger scale. In terms of access, time, and cost, non-probability sampling is often more efficient. Recruiting participants through convenience sampling, for example, can be done quickly and with minimal resources. This is particularly important for student researchers or small teams with limited budgets. Additionally, because AI usage among students may vary widely depending on factors like major, year in school, or familiarity with technology, a purposive sample can help ensure that the study includes participants who are most relevant to the research questions. Chapter 7 emphasizes that sampling decisions should align with the goals of the research. If the aim is to make statistical inferences about a population, probability sampling is ideal. But if the goal is to explore a phenomenon in depth and generate new ideas or theories, non-probability sampling is often more appropriate. In this case, my goal is not to generalize to all college students but to understand how a specific group interacts with ChatGPT. Therefore, non-probability sampling offers the flexibility and focus needed to conduct meaningful research in a timely and cost-effective way.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>2025-09-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-28.html#word-count-range-check",
    "href": "entries/2025-09-28.html#word-count-range-check",
    "title": "7  2025-09-28",
    "section": "7.3 Word Count & Range Check",
    "text": "7.3 Word Count & Range Check\n\n\n**Word count:** 480  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ✅ In range",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>2025-09-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-23.html",
    "href": "entries/2025-09-23.html",
    "title": "6  2025-09-23",
    "section": "",
    "text": "6.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>2025-09-23</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-23.html#choose-one-prompt-to-answer",
    "href": "entries/2025-09-23.html#choose-one-prompt-to-answer",
    "title": "6  2025-09-23",
    "section": "",
    "text": "Prompt A: Think of a broad media-related topic you’ve been curious about—something like influencer culture, algorithmic feeds, or news bias. Now, imagine you’re preparing to research this topic. Would you start with a research question or a hypothesis? Why? Reflect on how much you already know (or don’t know) about the topic, and how that affects whether exploration or prediction is the better fit.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>2025-09-23</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-23.html#response",
    "href": "entries/2025-09-23.html#response",
    "title": "6  2025-09-23",
    "section": "6.2 Response",
    "text": "6.2 Response\n\nOne media-related topic I’ve been curious about is the impact of electronic word-of-mouth (eWOM) on consumer decisions, especially when it comes to purchasing products that are new to the market. In today’s digital environment, eWOM—such as online reviews, social media posts, and influencer endorsements—has become a powerful force in shaping consumer behavior. While existing research and case studies suggest that positive eWOM can increase the likelihood of purchase, most of these studies focus on established products with a large volume of reviews and consumer feedback. This raises an important question: How do consumers decide to try a product when it is new to the market and lacks substantial eWOM? To explore this topic, I would begin with a research question rather than a hypothesis. Research questions are especially useful when a topic is still being explored and the researcher does not yet have enough information to make a specific prediction. A hypothesis, on the other hand, is better suited for situations where the researcher has enough background knowledge to make an educated guess about the outcome. Since I am still in the early stages of understanding how eWOM affects consumer behavior for new products, a research question allows me to remain open to multiple possibilities and perspectives. The chapter also emphasizes the importance of considering how much you already know about a topic when deciding between exploration and prediction. In my case, I’ve read a few case studies that suggest positive eWOM can influence purchasing decisions, but these studies typically involve products with established reputations. What I don’t yet understand is how consumers navigate uncertainty when a product is new and lacks reviews. Do they rely more heavily on influencer recommendations? Are they influenced by early adopters on platforms like TikTok or Reddit? Or do they wait until more feedback accumulates before making a decision? Because of this uncertainty, an exploratory approach is more appropriate. Starting with a research question like “How do consumers evaluate and decide to purchase a new-to-market product when eWOM is limited?” allows me to investigate the various factors that influence consumer trust and decision-making. These might include the credibility of the source, the format and tone of the eWOM, the platform it appears on, and the consumer’s own prior experiences or risk tolerance. Once I gather more data and insights, I may be able to refine my focus and develop a hypothesis for further testing. But for now, the goal is to explore the landscape of consumer behavior in the context of emerging products and limited digital feedback. This approach aligns well with the principles outlined in Chapter 6, which encourages researchers to start with curiosity and open-ended inquiry when entering a new area of study.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>2025-09-23</span>"
    ]
  },
  {
    "objectID": "entries/2025-09-23.html#word-count-range-check",
    "href": "entries/2025-09-23.html#word-count-range-check",
    "title": "6  2025-09-23",
    "section": "6.3 Word Count & Range Check",
    "text": "6.3 Word Count & Range Check\n\n\n**Word count:** 458  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ✅ In range",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>2025-09-23</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-07.html",
    "href": "entries/2025-10-07.html",
    "title": "8  2025-10-07",
    "section": "",
    "text": "8.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>2025-10-07</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-07.html#choose-one-prompt-to-answer",
    "href": "entries/2025-10-07.html#choose-one-prompt-to-answer",
    "title": "8  2025-10-07",
    "section": "",
    "text": "Prompt C: Think about a time you were measured or evaluated—maybe on a test, a performance review, or even a personality quiz. Did the measure feel reliable (consistent)? Did it feel valid (accurate)? Explain your experience and how it relates to the difference between reliability and validity. Why is it essential for a measure to be both? Which one seems more complicated to achieve, and why?",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>2025-10-07</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-07.html#response",
    "href": "entries/2025-10-07.html#response",
    "title": "8  2025-10-07",
    "section": "8.2 Response",
    "text": "8.2 Response\n\nOne of the most memorable times I was evaluated was during high school when I took the SAT. As someone who has grown up with ADHD, I found the experience particularly challenging and frustrating. The SAT is designed to measure academic readiness for college, but for me, it didn’t feel like an accurate reflection of my abilities—especially in the English section. My math score was average, which aligned with my classroom performance, but my English score was significantly below average. This result surprised me because I had always done reasonably well in English classes and felt confident in my reading and writing skills. After receiving my initial scores, I enrolled in a prep course that focused on test-taking strategies and familiarized me with the types of questions on the SAT. With practice and guidance, I was able to dramatically improve my English score on the retake. This experience highlighted a key issue with the validity of the SAT for someone like me. Validity refers to how well a test measures what it claims to measure. In my case, the SAT didn’t accurately measure my knowledge or potential in English—it measured how well I could perform under timed, high-pressure conditions that are particularly difficult for individuals with ADHD. The improvement in my score after taking a prep course suggests that the test was more about mastering its format than demonstrating true academic ability. On the other hand, I do believe the SAT is reliable, meaning it produces consistent results under similar conditions. The structure, timing, and scoring are standardized, so if someone takes the test multiple times without any changes in preparation, their scores are likely to be similar. Reliability is important because it ensures fairness in how people are evaluated. However, a test can be reliable without being valid. That’s what I experienced—the SAT consistently measured my ability to take that specific kind of test, but not necessarily my actual knowledge or potential. This distinction between reliability and validity is crucial in any kind of evaluation. A measure needs to be both consistent and accurate to be truly useful. If a test is reliable but not valid, it may consistently give misleading results. If it’s valid but not reliable, the results may vary too much to be trusted. In educational and psychological assessments, both qualities are essential to ensure fair and meaningful evaluations. Between the two, I think validity is more difficult to achieve. Reliability can often be ensured through standardization and repetition, but validity requires a deeper understanding of what is being measured and how different factors—like learning differences, cultural background, or test anxiety—can affect outcomes. Designing a test that accurately reflects diverse abilities and experiences is a complex challenge, especially when trying to apply it broadly across populations.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>2025-10-07</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-07.html#word-count-range-check",
    "href": "entries/2025-10-07.html#word-count-range-check",
    "title": "8  2025-10-07",
    "section": "8.3 Word Count & Range Check",
    "text": "8.3 Word Count & Range Check\n\n\n**Word count:** 469  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ✅ In range",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>2025-10-07</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-13.html",
    "href": "entries/2025-10-13.html",
    "title": "9  2025-10-13",
    "section": "",
    "text": "9.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>2025-10-13</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-13.html#choose-one-prompt-to-answer",
    "href": "entries/2025-10-13.html#choose-one-prompt-to-answer",
    "title": "9  2025-10-13",
    "section": "",
    "text": "Prompt C: Why do you think people often ignore or skip surveys? From your perspective as both a respondent and future researcher, what strategies would make you more likely to complete a survey? How do your answers shape the way researchers must think about sampling and nonresponse?",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>2025-10-13</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-13.html#response",
    "href": "entries/2025-10-13.html#response",
    "title": "9  2025-10-13",
    "section": "9.2 Response",
    "text": "9.2 Response\n\nPeople often ignore or skip surveys for several reasons, and one of the biggest factors is the lack of incentive. In today’s digital environment, where notifications and distractions are constant, it’s easy to dismiss a survey without a second thought. When someone opens their phone, they usually have a specific purpose—checking messages, scrolling social media, or completing a quick task. A survey feels like an interruption to their task, rather than a priority. This is compounded by the fact that attention spans are shrinking; if a survey appears long, dense, or time-consuming, respondents are likely to abandon it midway, start to take on another task, or avoid starting it altogether. Another major issue is trust. With the rise of spam, phishing attempts, and fake messages, people are cautious about sharing personal information through online surveys. If a survey doesn’t clearly communicate its legitimacy or not designed with a modern appeal, respondents may fear that their data will be misused. This skepticism creates a barrier that researchers must overcome to collect accurate and representative data. From my perspective as both a respondent and a future researcher, several strategies could make me more likely to complete a survey. First, transparency is key. Clearly stating who is conducting the survey, why the data is being collected, if the data will be protected, and how it will be used builds trust. Second, incentives matter—but they need to be realistic and obtainable. Even small rewards, like discounts or entries into a prize drawing, can motivate participation. Third, surveys should be short and user-friendly. Breaking questions into manageable sections, having the ability to save your progress, and using engaging formats (such as progress bars) can reduce fatigue and encourage completion. Finally, reminders help. A gentle follow-up email or notification can prompt respondents who intended to participate but forgot. These answers have important implications for researchers when thinking about sampling and nonresponse. If certain groups are more likely to ignore surveys—such as those with limited time or high skepticism—nonresponse bias can distort results. Researchers must design strategies to minimize this bias, such as oversampling hard-to-reach populations or using mixed methods (online, phone, in-person) to increase accessibility. They also need to consider how incentives and trust-building measures affect participation rates across different demographics. Ultimately, understanding why people skip surveys helps researchers create more inclusive and effective sampling plans, ensuring that data reflects the diversity of the population rather than just those who are easiest to reach. In short, ignoring surveys is often a matter of convenience, trust, and perceived value. By addressing these factors through transparency, incentives, simplicity, and reminders, researchers can improve response rates and reduce bias—leading to more accurate and meaningful insights.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>2025-10-13</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-13.html#word-count-range-check",
    "href": "entries/2025-10-13.html#word-count-range-check",
    "title": "9  2025-10-13",
    "section": "9.3 Word Count & Range Check",
    "text": "9.3 Word Count & Range Check\n\n\n**Word count:** 0  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ❌ Out of range",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>2025-10-13</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-21.html",
    "href": "entries/2025-10-21.html",
    "title": "10  2025-10-21",
    "section": "",
    "text": "10.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>2025-10-21</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-21.html#choose-one-prompt-to-answer",
    "href": "entries/2025-10-21.html#choose-one-prompt-to-answer",
    "title": "10  2025-10-21",
    "section": "",
    "text": "Prompt C: Experiments often require researchers to deceive participants or control aspects of their environment. Reflect on how you feel about that. Do you think the benefits of experimental knowledge are worth these trade-offs? What would be essential to include in your debrief if you had to deceive participants in your study?",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>2025-10-21</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-21.html#response",
    "href": "entries/2025-10-21.html#response",
    "title": "10  2025-10-21",
    "section": "10.2 Response",
    "text": "10.2 Response\n\nAs someone who tends to be skeptical, I often question whether the benefits of experimental knowledge are always worth the ethical trade-offs, especially when deception or manipulation is involved. While I understand that experiments are essential for advancing science and improving our understanding of human behavior, I believe there are limits to what should be considered acceptable in research practices. In particular, I’m concerned about experiments in the medical field where new drugs or treatments are tested without fully understanding their potential effects. The risks to participants can be significant, and I don’t always trust that every study is conducted with the highest ethical standards. History has shown us that unethical research can have devastating consequences, and that makes me cautious about supporting studies that involve deception or manipulation without clear safeguards. That said, I do recognize that some experiments—especially those that do not cause physical or psychological harm—can yield valuable insights that benefit society. For example, behavioral studies that involve minor deception, such as withholding the true purpose of the study to prevent bias, can be acceptable if they are conducted responsibly. In these cases, the knowledge gained can outweigh the minimal risks involved, provided that participants are treated with respect and care throughout the process. If I were conducting a study that required deception, I would only use it as a last resort—after thoroughly exploring all non-deceptive alternatives. The deception would need to be as minimal and non-invasive as possible, and I would take every precaution to ensure that it does not cause psychological distress or harm. The ethical principle of “do no harm” should always guide research decisions. A comprehensive debriefing would be absolutely essential following the study. During the debrief, I would clearly explain the nature and purpose of the deception, why it was necessary, and how it contributed to the research goals. I would also provide participants with the opportunity to ask questions and express any concerns they might have. Addressing any emotional or psychological discomfort would be a top priority, and I would ensure that participants leave the study feeling respected and valued. Additionally, I would make sure that participants are fully informed of their rights both before and after the study. This includes the right to withdraw at any time, the right to confidentiality, and the right to access support if needed. Transparency and respect are key to maintaining ethical standards in research, especially when deception is involved. In conclusion, while I remain cautious about the use of deception in experiments, I acknowledge that it can be a useful tool when applied ethically and responsibly. The benefits of experimental knowledge can be significant, but they should never come at the expense of participant well-being. Ethical research must prioritize informed consent, minimize harm, and ensure that participants are treated with dignity throughout the entire process.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>2025-10-21</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-21.html#word-count-range-check",
    "href": "entries/2025-10-21.html#word-count-range-check",
    "title": "10  2025-10-21",
    "section": "10.3 Word Count & Range Check",
    "text": "10.3 Word Count & Range Check\n\n\n**Word count:** 476  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ✅ In range",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>2025-10-21</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-28.html",
    "href": "entries/2025-10-28.html",
    "title": "11  2025-10-28",
    "section": "",
    "text": "11.1 Choose one prompt to answer",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>2025-10-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-28.html#choose-one-prompt-to-answer",
    "href": "entries/2025-10-28.html#choose-one-prompt-to-answer",
    "title": "11  2025-10-28",
    "section": "",
    "text": "Prompt A: Think about a media environment you engage with regularly—TikTok, news headlines, TV dramas, YouTube comments, etc. Choose one and describe a research question that could be answered through content analysis. What would you want to measure? Would you be more interested in manifest content (what’s there) or latent content (the underlying tone or message), and why?",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>2025-10-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-28.html#response",
    "href": "entries/2025-10-28.html#response",
    "title": "11  2025-10-28",
    "section": "11.2 Response",
    "text": "11.2 Response\n\nOne media environment I engage with frequently is Instagram, particularly content related to gentle parenting. This topic has gained significant traction on the platform, with influencers and everyday users sharing videos, infographics, and personal stories that promote a more empathetic and emotionally attuned approach to parenting. A research question I would explore through content analysis is: How is gentle parenting portrayed and received in Instagram posts by top influencers? This question allows for a deeper understanding of both the messaging around gentle parenting and the public’s reaction to it, especially in the comment sections where opinions and debates often unfold. To conduct this study, I would focus on a sample of high-engagement posts from influencers who consistently share gentle parenting content. These posts often include explanations of parenting strategies, demonstrations of parent-child interactions, or reflections on parenting challenges. I would analyze both the content of the posts and the comments they receive. Specifically, I’d measure the frequency of gentle parenting themes such as emotional validation, non-punitive discipline, and child autonomy. Additionally, I’d examine the sentiment expressed in user comments—whether they are supportive, critical, or neutral—and identify recurring patterns of controversy or disagreement. While manifest content, such as specific words, hashtags, or emojis, can provide useful surface-level data, I would be more interested in analyzing latent content. Latent content refers to the underlying tone, values, and emotional messaging embedded in the posts and comments. For example, even if a comment doesn’t explicitly criticize gentle parenting, its tone might suggest skepticism or sarcasm, which reveals deeper cultural attitudes. By focusing on latent content, I could uncover how gentle parenting is framed—whether it’s seen as progressive, permissive, idealistic, or unrealistic—and how these perceptions vary across different audiences. This approach aligns with the principles outlined in Chapter 11 of the coursepack, which emphasizes the importance of defining clear units of analysis and distinguishing between manifest and latent content. In this case, the units of analysis would include individual Instagram posts and their associated comment threads. Coding categories might include emotional tone, parenting values, types of support or criticism, and references to broader social norms. The goal would be to systematically interpret the content in a way that reveals not just what is being said, but how it reflects larger cultural conversations about parenting. Ultimately, this research could contribute to a better understanding of how social media shapes and reflects parenting ideologies. It could also highlight the role of influencers in promoting certain values and the ways in which audiences engage with or resist those messages. By using content analysis to explore this dynamic media environment, I would gain insight into the evolving discourse around parenting and the emotional and ideological tensions that surface in digital spaces.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>2025-10-28</span>"
    ]
  },
  {
    "objectID": "entries/2025-10-28.html#word-count-range-check",
    "href": "entries/2025-10-28.html#word-count-range-check",
    "title": "11  2025-10-28",
    "section": "11.3 Word Count & Range Check",
    "text": "11.3 Word Count & Range Check\n\n\n**Word count:** 461  \n\n\n**Required range (MC501):** 450–500 words  \n\n\n**Status:** ✅ In range",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>2025-10-28</span>"
    ]
  }
]