---
title: "2025-11-12"
format:
  html: default
  pdf: default
params:
  course: "mc501"
  word_min: 450
  word_max: 500
  p1: 'Think about a variable you’ve seen reported often—something like income, grades, or social media followers. Was it reported as an average (mean)? Do you think that number accurately reflected the “typical” case? Based on what you learned in this chapter, would another measure of central tendency (median or mode) have been more appropriate? Why?'
 
---

## Choose **one** prompt to answer

> **Prompt A:** `r params$p1`


---

## Response

<!-- RESPONSE-START -->
As the social media coordinator at Southern Illinois University Edwardsville, I regularly review analytics and compile semester reports. These reports include metrics such as net follower growth, engagement rate, and average view time. Two of the most commonly reported statistics—average engagement and average view time—are presented as means. While the mean is a widely used measure of central tendency, I’ve noticed that it doesn’t always accurately reflect our typical performance across a semester.
For example, engagement data can be heavily influenced by outliers. During periods like winter break or Thanksgiving break, student activity on social media drops significantly because most students are off campus. These weeks pull the average engagement rate downward, even though they don’t represent the usual level of interaction during the semester. Conversely, special events such as Homecoming or a major athletics victory can cause engagement to spike dramatically. These high-performing posts inflate the mean, making it seem like engagement was consistently strong when, in reality, those peaks were isolated.
This illustrates a key limitation of the mean: it is sensitive to extreme values. When data includes outliers—whether unusually high or low—the mean can give a misleading picture of what is “typical.” Based on what I learned in Chapter 13, the median might be a better measure of central tendency for engagement data. The median represents the middle value when all observations are ordered, so it is less affected by outliers. Using the median would provide a clearer sense of what a typical post’s engagement looks like, regardless of whether a few posts performed exceptionally well or poorly.
The mode could also be useful in certain cases, especially if we wanted to know the most common engagement level. However, engagement data tends to be continuous rather than categorical, so the mode might not be as informative as the median. For our purposes—summarizing overall performance—the median seems most appropriate because it balances the influence of extreme highs and lows.
In practice, reporting both the mean and median could offer the most complete picture. The mean would still be valuable for understanding overall trends, while the median would help stakeholders interpret what is typical. For example, if the mean engagement rate is 8% but the median is 5%, that discrepancy signals that a few high-performing posts are skewing the average. This insight could guide strategy: rather than assuming all posts perform near 8%, we’d recognize that most posts hover around 5%, and plan accordingly.
In short, while averages are convenient, they don’t always tell the whole story. For social media analytics—where engagement can fluctuate due to seasonal breaks and special events—the median is often a more accurate reflection of typical performance.

<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
